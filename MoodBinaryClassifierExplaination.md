
# ğŸ§  Mood Classification (Happy / Not Happy)

### **A Complete Step-By-Step Explanation of the Binary Image Classification Model**

This notebook builds a **binary image classification model** using  **TensorFlow** , classifying images into:

* **Happy ğŸ˜€**
* **Not Happy ğŸ˜**

Every cell is explained so that even a **beginner** can understand what's happening in the code.

---

## ğŸ–¥ï¸ **Cell 1 â€” Check GPU Availability**

```python
!nvidia-smi
```

This command shows if Google Colab has given us a  **GPU** .

A GPU makes deep learning  **faster** .

---

## ğŸ“¦ **Cell 2 â€” Import Required Libraries**

```python
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.preprocessing import image
import matplotlib.pyplot as plt
import tensorflow as tf
import numpy as np
import cv2
import os
```

**What these do:**

* `ImageDataGenerator` â€“ Loads images from folders & prepares them for training.
* `image` â€“ Helps load individual images.
* `matplotlib` â€“ To display images.
* `tensorflow` â€“ To build the deep learning model.
* `numpy` â€“ For numerical operations.
* `cv2` â€“ For reading images.
* `os` â€“ To work with folders.

---

## ğŸ–¼ï¸ **Cell 3 â€” Load a Sample Image**

```python
img = image.load_img('/content/drive/MyDrive/training/happy/k3.jpg')
```

Loads an image from the **happy** folder to check where we are working.

---

## ğŸ–¼ï¸ **Cell 4 â€” Display the Loaded Image**

```python
plt.imshow(img)
```

Shows the image you loaded â€” useful for verification.

---

## ğŸ§ª **Cell 5 â€” Read Image Using OpenCV**

```python
i1 = cv2.imread('/content/drive/MyDrive/training/happy/k3.jpg')
i1
```

Reads the same image using OpenCV.

OpenCV loads images as  **NumPy arrays** .

---

## ğŸ“ **Cell 6 â€” Check Image Shape**

```python
i1.shape
```

Shows  **height, width, channels** , e.g.:

`(200, 200, 3)`

(3 = RGB channels)

---

## ğŸ§½ **Cell 7 â€” Create Training & Validation Generators**

```python
train  = ImageDataGenerator(rescale=1/200)
validation = ImageDataGenerator(rescale=1/200)
```

`rescale=1/200` reduces pixel values from (0â€“255) to (0â€“1.27).

Scaling helps the neural network learn better.

---

## ğŸ“š **Cell 8 â€” Load Training & Validation Image Folders**

```python
train_dataset = train.flow_from_directory('/content/drive/MyDrive/training',
                                          target_size = (200,200),
                                          batch_size = 32,
                                          class_mode = 'binary')

validation = validation.flow_from_directory('/content/drive/MyDrive/validation',
                                            target_size = (200,200),
                                            batch_size = 32,
                                            class_mode = 'binary')
```

This automatically:

* Reads images from your folder structure
* Converts them to 200Ã—200
* Bundles them in batches of 32
* Labels them as **0** or **1** (Binary)

Folder structure expected:

```
training/
    happy/
    nothappy/
validation/
    happy/
    nothappy/
```

---

## ğŸ·ï¸ **Cell 9 â€” See Class Labels**

```python
train_dataset.class_indices
```

Shows which class is **0** and which is  **1** . Example:

```
{'happy': 0, 'nothappy': 1}
```

---

## ğŸ”¢ **Cell 10 â€” Numerical Class Values**

```python
train_dataset.classes
```

Lists all class labels assigned to each image.

---

## ğŸ§  **Cell 11 â€” Build the CNN Model**

```python
model = tf.keras.models.Sequential([
    tf.keras.layers.Conv2D(16,(3,3),activation='relu',input_shape=(200,200,3)),
    tf.keras.layers.MaxPool2D(2,2),

    tf.keras.layers.Conv2D(32,(3,3),activation='relu'),
    tf.keras.layers.MaxPool2D(2,2),

    tf.keras.layers.Conv2D(64,(3,3),activation='relu'),
    tf.keras.layers.MaxPool2D(2,2),

    tf.keras.layers.Flatten(),

    tf.keras.layers.Dense(512, activation='relu'),

    tf.keras.layers.Dense(1, activation='sigmoid')
])
```

### Layer-by-layer explanation:

#### ğŸ“Œ **1. Convolution Layers**

Detects patterns like:

* Eyes
* Mouth
* Face structure

#### ğŸ“Œ **2. MaxPooling**

Reduces image size â†’ faster training.

#### ğŸ“Œ **3. Flatten**

Converts 2D features to a single long vector.

#### ğŸ“Œ **4. Dense(512)**

Learns patterns like:

* Smile shape
* Lip curve
* Eye squeeze

#### ğŸ“Œ **5. Output Layer**

`Dense(1, activation='sigmoid')`

* Outputs a value between **0 and 1**
* If **< 0.5 â†’ Happy**
* If **â‰¥ 0.5 â†’ Not Happy**

---

## âš™ï¸ **Cell 12 â€” Compile the CNN Model**

```python
model.compile(
    loss='binary_crossentropy',
    optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.001),
    metrics=['accuracy']
)
```

 **Loss** : Best for binary classification

 **Optimizer** : RMSprop (good for small datasets)

 **Metric** : Accuracy

---

## ğŸ‹ï¸ **Cell 13 â€” Train the Model**

```python
model_fit = model.fit(train_dataset, epochs=15)
```

This:

* Uses training images
* Trains for 15 complete cycles (epochs)
* Learns to classify Happy vs Not Happy

---

## ğŸ—‚ï¸ **Cell 14 â€” List Testing Folder**

```python
dir_path = '/content/drive/MyDrive/testing'
for i in os.listdir(dir_path):
  print(i)
```

Shows all files inside  **testing folder** .

---

## ğŸ‘ï¸ **Cell 15 â€” Display Test Images**

```python
for i in os.listdir(dir_path):
     img = image.load_img(dir_path+'//'+i,target_size=(200,200))
     plt.imshow(img)
     plt.show()
```

Displays each test image one by one.

---

## ğŸ” **Cell 16 â€” Predict Mood for Each Test Image**

```python
x = image.img_to_array(img)
x = np.expand_dims(x,axis=0)
images = np.vstack([x])

val = model.predict(images)

if val == 0:
    print("i am happy")
else:
    print("i am not happy")
```

### How it works:

* Convert image â†’ array
* Add batch dimension
* Pass to the model
* Model outputs **0** or **1**

---

## âš¡ **Cell 17 â€” GPU Info Again**

```python
!nvidia-smi
```

Checks GPU after training.

---

# ğŸŒ Cell 18 â€” Define Prediction Function for Gradio App

```python
def predict_mood(image):
    img = image.resize((200,200))
    x = np.array(img)
    x = np.expand_dims(x,axis=0)
    val = model.predict(x)[0][0]

    if val < 0.5:
        return "Happy"
    else:
        return "Not happy"
```

This function:

* Resizes the uploaded image
* Converts it to an array
* Passes it to the model
* Returns the predicted mood

---

# ğŸ›ï¸ Cell 19 â€” Create Gradio Web App Interface

```python
iface = gr.Interface(
    fn=predict_mood,
    inputs = gr.Image(type='pil',label="Upload an Image"),
    outputs = gr.Text(label="Predict Mood"),
    title = "Mood Classification (Happy/Not happy)",
    description = "Upload an image to classify if the person is happy or not happy"
)

iface.launch()
```

This makes a **simple web app** where the user can:

* Upload ANY image
* Model returns **Happy / Not Happy**

Perfect for real-time testing!
